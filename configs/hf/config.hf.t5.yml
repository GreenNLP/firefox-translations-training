####
# Example of a production config
# Change language pair, experiment name, datasets and other settings if needed
# Training low resource languages might require more tuning of pipeline/training/configs
###

experiment:
  dirname: hf
  name: t5
  langpairs:
    - en-de

  split-length: 1000

  best-model: perplexity
  
  huggingface:
    modelname: "google-t5/t5-small"
    modelclass: "transformers.AutoModelForSeq2SeqLM"
    lang_tags:
      en: English
      de: German
    prompt: "Translate {src_lang} to {tgt_lang}: {source}"
    config:
      max_new_tokens: 150

datasets:
  train:
    - ELRC_2922__v1
  devtest:
    - flores_dev
  test:
    - flores_devtest