####
# Example of a production config
# Change language pair, experiment name, datasets and other settings if needed
# Training low resource languages might require more tuning of pipeline/training/configs
###

experiment:
  dirname: fiu-gmw
  name: fiu-en
  langpairs:
    - et-en
    - fi-en

  #URL to the OPUS-MT model to use as the teacher
  opusmt-teacher: "https://object.pouta.csc.fi/Tatoeba-MT-models/fiu-gmw/opus-2021-02-18.zip"
  
  # Specify if the teacher and the student are many2one
  one2many-teacher: True
  one2many-student: False

  #URL to the OPUS-MT model to use as the backward model
  opusmt-backward: "https://object.pouta.csc.fi/Tatoeba-MT-models/eng-fiu/opus2m-2020-08-01.zip"
  one2many-backward: True

  teacher-ensemble: 1
  
  parallel-max-sentences: 100000
  split-length: 10000
  spm-vocab-size: 400 #Because we are dealing with very little data

  best-model: perplexity

datasets:
  train:
    - opus_ELRC_2922/v1
  devtest:
    - flores_dev
  test:
    - flores_devtest